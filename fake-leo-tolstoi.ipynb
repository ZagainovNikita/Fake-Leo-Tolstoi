{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 4900073,
     "sourceType": "datasetVersion",
     "datasetId": 2841576
    }
   ],
   "dockerImageVersionId": 30587,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "with open(\"/kaggle/input/warandpeacetxt/book-war-and-peace.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-29T14:55:57.277504Z",
     "iopub.execute_input": "2023-11-29T14:55:57.277873Z",
     "iopub.status.idle": "2023-11-29T14:55:57.444049Z",
     "shell.execute_reply.started": "2023-11-29T14:55:57.277841Z",
     "shell.execute_reply": "2023-11-29T14:55:57.443228Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "char_set = sorted(list(set(text)))\n",
    "VOCAB_SIZE = len(char_set)\n",
    "print(VOCAB_SIZE)\n",
    "print(''.join(char_set))"
   ],
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:02.144821Z",
     "iopub.execute_input": "2023-11-29T14:56:02.145707Z",
     "iopub.status.idle": "2023-11-29T14:56:02.206149Z",
     "shell.execute_reply.started": "2023-11-29T14:56:02.145662Z",
     "shell.execute_reply": "2023-11-29T14:56:02.205375Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "82\n\n !\"'()*,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzàäéê\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "word_index = {char: ind for ind, char in enumerate(char_set)}\n",
    "index_word = {ind: char for ind, char in enumerate(char_set)}\n",
    "encoder = lambda x: [word_index.get(i, len(word_index)) for i in x]\n",
    "decoder = lambda x: ''.join([index_word.get(ind, \"<OOV>\") for ind in x])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:02.415448Z",
     "iopub.execute_input": "2023-11-29T14:56:02.415788Z",
     "iopub.status.idle": "2023-11-29T14:56:02.420972Z",
     "shell.execute_reply.started": "2023-11-29T14:56:02.415757Z",
     "shell.execute_reply": "2023-11-29T14:56:02.420226Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "data = torch.tensor(encoder(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:02.677352Z",
     "iopub.execute_input": "2023-11-29T14:56:02.677718Z",
     "iopub.status.idle": "2023-11-29T14:56:03.415821Z",
     "shell.execute_reply.started": "2023-11-29T14:56:02.677686Z",
     "shell.execute_reply": "2023-11-29T14:56:03.415043Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": "torch.Size([3202303]) torch.int64\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_size = int(0.9 * len(data))\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:03.417144Z",
     "iopub.execute_input": "2023-11-29T14:56:03.417399Z",
     "iopub.status.idle": "2023-11-29T14:56:03.423272Z",
     "shell.execute_reply.started": "2023-11-29T14:56:03.417371Z",
     "shell.execute_reply": "2023-11-29T14:56:03.422655Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, seq_length, head_hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.seq_length = seq_length\n",
    "        self.head_hidden_dim = head_hidden_dim\n",
    "        self.hidden_dim = num_heads * head_hidden_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.to_QKV = nn.Linear(self.hidden_dim, self.hidden_dim * 3)\n",
    "        self.projection = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q, k, v = self.to_QKV(x).split(self.hidden_dim, dim=2)\n",
    "        k = k.view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) \n",
    "        q = q.view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) \n",
    "        v = v.view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2) \n",
    "        \n",
    "        attention = F.scaled_dot_product_attention(q, k, v, is_causal=True, dropout_p=self.dropout)\n",
    "        attention = attention.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        return attention\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, ff_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(ff_dim, hidden_dim)\n",
    "         )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_heads, seq_length, hidden_dim, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.head_hidden_dim = hidden_dim // num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.multi_head_attention = MultiHeadAttention(self.num_heads, \n",
    "                                                       self.seq_length, \n",
    "                                                       self.head_hidden_dim,\n",
    "                                                       self.dropout)\n",
    "        self.feed_forward = FeedForward(self.hidden_dim, self.ff_dim, self.dropout)\n",
    "        self.norm1 = nn.LayerNorm(self.hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(self.hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attention = self.multi_head_attention(self.norm1(x))\n",
    "        feed_forward = self.feed_forward(self.norm2(attention + x))\n",
    "        output = feed_forward + x\n",
    "        return output\n",
    "    \n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, num_layers, vocab_size, num_heads, seq_length, hidden_dim, ff_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.position_embedding = nn.Embedding(seq_length, hidden_dim)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(num_heads, seq_length, hidden_dim, ff_dim, dropout) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.linear_head = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "        \n",
    "        tok_embed = self.token_embedding(x)\n",
    "        pos_embed = self.position_embedding(torch.arange(T, device=device))\n",
    "        \n",
    "        embed = tok_embed + pos_embed\n",
    "        context_embeds = self.blocks(embed)\n",
    "        normalized_embeds = self.norm(context_embeds)\n",
    "        logits = self.linear_head(normalized_embeds)\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, x, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            chunk = x[:, -self.seq_length:]\n",
    "            logits, _ = self(chunk)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            new_token = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat((x, new_token), dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:03.424187Z",
     "iopub.execute_input": "2023-11-29T14:56:03.424458Z",
     "iopub.status.idle": "2023-11-29T14:56:03.442669Z",
     "shell.execute_reply.started": "2023-11-29T14:56:03.424433Z",
     "shell.execute_reply": "2023-11-29T14:56:03.442054Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 256\n",
    "CHUNK_SIZE = 320\n",
    "N_EPOCHS = 200\n",
    "EVAL_INTERVAL = 1\n",
    "LEARNING_RATE = 6e-5\n",
    "EVAL_ITERS = 20\n",
    "HIDDEN_DIM = 512\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 8\n",
    "DROPOUT = 0.2\n",
    "FF_DIM = 2048"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:03.814278Z",
     "iopub.execute_input": "2023-11-29T14:56:03.814640Z",
     "iopub.status.idle": "2023-11-29T14:56:03.818702Z",
     "shell.execute_reply.started": "2023-11-29T14:56:03.814609Z",
     "shell.execute_reply": "2023-11-29T14:56:03.818029Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_batch(split):\n",
    "    data = (train_data if split == \"train\" else test_data)\n",
    "    start_ind = random.randint(0, len(data)-CHUNK_SIZE-1)\n",
    "    x = data[start_ind: start_ind+CHUNK_SIZE]\n",
    "    y = data[start_ind+1: start_ind+CHUNK_SIZE+1]\n",
    "    return x, y\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, generator, length):\n",
    "        self.generator = generator\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return next(self.generator)\n",
    "\n",
    "# Example generator function\n",
    "def train_generator():\n",
    "    while True:\n",
    "        yield get_batch('train')\n",
    "        \n",
    "def test_generator():\n",
    "    while True:\n",
    "        yield get_batch('test')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:04.747111Z",
     "iopub.execute_input": "2023-11-29T14:56:04.747504Z",
     "iopub.status.idle": "2023-11-29T14:56:04.754322Z",
     "shell.execute_reply.started": "2023-11-29T14:56:04.747469Z",
     "shell.execute_reply": "2023-11-29T14:56:04.753641Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def get_batch(split):\n",
    "    data = (train_data if split == \"train\" else test_data)\n",
    "    start_ind = random.randint(0, len(data)-CHUNK_SIZE-1)\n",
    "    x = data[start_ind: start_ind+CHUNK_SIZE]\n",
    "    y = data[start_ind+1: start_ind+CHUNK_SIZE+1]\n",
    "    return x, y"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:05.253647Z",
     "iopub.execute_input": "2023-11-29T14:56:05.254038Z",
     "iopub.status.idle": "2023-11-29T14:56:05.259715Z",
     "shell.execute_reply.started": "2023-11-29T14:56:05.254005Z",
     "shell.execute_reply": "2023-11-29T14:56:05.258853Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "\n",
    "train_dataset = GPTDataset(generator=train_generator(), length=EVAL_ITERS*BATCH_SIZE)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "def _mp_fn(rank, flags):\n",
    "    xm.rendezvous('init')\n",
    "    device = xm.xla_device()\n",
    "    mp_device_train_loader = pl.MpDeviceLoader(train_dataloader, device)\n",
    "    gpt = GPT(num_layers=NUM_LAYERS, \n",
    "              vocab_size=VOCAB_SIZE, \n",
    "              num_heads=NUM_HEADS, \n",
    "              seq_length=CHUNK_SIZE, \n",
    "              hidden_dim=HIDDEN_DIM, \n",
    "              ff_dim=FF_DIM, \n",
    "              dropout=DROPOUT)\n",
    "    gpt.load_state_dict(torch.load('/kaggle/working/trained_model_after_90_epochs_4gramm.pth'))\n",
    "    gpt = gpt.to(device)\n",
    "    optimizer = torch.optim.AdamW(gpt.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        for x_batch, y_batch in mp_device_train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits, loss = gpt(x_batch, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer)\n",
    "            print(loss, epoch)\n",
    "        if (epoch > 0) and (epoch % 10 == 0):\n",
    "            torch.save(gpt.state_dict(), f\"trained_model_after_{epoch}_epochs.pth\")\n",
    "    torch.save(gpt.state_dict(), \"FINAL_MODEL.pth\")\n",
    "            \n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')"
   ],
   "metadata": {
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2023-11-29T14:56:24.447941Z",
     "iopub.execute_input": "2023-11-29T14:56:24.448785Z",
     "iopub.status.idle": "2023-11-29T15:27:48.015719Z",
     "shell.execute_reply.started": "2023-11-29T14:56:24.448745Z",
     "shell.execute_reply": "2023-11-29T15:27:48.014620Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": "tensor(1.6170, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.8438, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6520, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6834, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.7237, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6914, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6561, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6387, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6427, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6372, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6370, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6481, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6330, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6208, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6142, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6161, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6213, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6108, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6274, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6037, device='xla:0', grad_fn=<NllLossBackward0>) 1\ntensor(1.6258, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6172, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6141, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6041, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5975, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6169, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5980, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6015, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5966, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6070, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6126, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5989, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6159, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6240, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5964, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6026, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5991, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6016, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6062, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.6056, device='xla:0', grad_fn=<NllLossBackward0>) 2\ntensor(1.5984, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6014, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5934, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6037, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6067, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5975, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6020, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6100, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5969, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5864, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6082, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5982, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6150, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5978, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5745, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5875, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5857, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6039, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.5971, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6119, device='xla:0', grad_fn=<NllLossBackward0>) 3\ntensor(1.6059, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6029, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5829, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5816, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6214, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5924, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5942, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5818, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5917, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5917, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5920, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5764, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6077, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5775, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6157, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6034, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6120, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5830, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5800, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.6055, device='xla:0', grad_fn=<NllLossBackward0>) 4\ntensor(1.5888, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5854, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5969, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5985, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5824, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5801, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.6021, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5854, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5993, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5904, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5788, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5855, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5915, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5862, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5872, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.6008, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.6000, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5978, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5754, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5960, device='xla:0', grad_fn=<NllLossBackward0>) 5\ntensor(1.5895, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5804, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5745, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5799, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5902, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5884, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5999, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.6007, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5766, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5905, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5905, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5933, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5998, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5772, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5839, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5931, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5912, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5802, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5847, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5806, device='xla:0', grad_fn=<NllLossBackward0>) 6\ntensor(1.5787, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5803, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5803, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5875, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5881, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5769, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5864, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5913, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5827, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5941, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5865, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5934, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5905, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5811, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5791, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.6018, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5943, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5768, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5905, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5913, device='xla:0', grad_fn=<NllLossBackward0>) 7\ntensor(1.5895, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5815, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5782, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5809, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5803, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5783, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5724, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5858, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5926, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5758, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5638, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5715, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5792, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5862, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5793, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5849, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5690, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5713, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5795, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5923, device='xla:0', grad_fn=<NllLossBackward0>) 8\ntensor(1.5646, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5706, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5821, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5788, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5807, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5817, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5767, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5982, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5802, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5780, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5766, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5766, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5654, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5790, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5730, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5794, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5802, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5806, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5721, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5723, device='xla:0', grad_fn=<NllLossBackward0>) 9\ntensor(1.5728, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5853, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5838, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5748, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5751, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5814, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5568, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5734, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5723, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5767, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5815, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5776, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5827, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5817, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5637, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5687, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5630, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5798, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5656, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5712, device='xla:0', grad_fn=<NllLossBackward0>) 10\ntensor(1.5625, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5734, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5648, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5565, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5555, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5807, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5601, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5836, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5623, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5808, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5735, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5645, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5698, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5862, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5559, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5803, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5789, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5574, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5741, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5644, device='xla:0', grad_fn=<NllLossBackward0>) 11\ntensor(1.5570, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5541, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5736, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5766, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5586, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5530, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5591, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5627, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5733, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5544, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5590, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5644, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5616, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5645, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5634, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5544, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5518, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5779, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5726, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5664, device='xla:0', grad_fn=<NllLossBackward0>) 12\ntensor(1.5461, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5672, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5599, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5572, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5525, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5436, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5620, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5473, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5696, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5696, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5507, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5508, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5685, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5693, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5610, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5532, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5587, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5464, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5516, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5610, device='xla:0', grad_fn=<NllLossBackward0>) 13\ntensor(1.5579, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5501, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5388, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5563, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5638, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5631, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5525, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5538, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5597, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5549, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5565, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5547, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5567, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5476, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5464, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5520, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5577, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5503, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5518, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5555, device='xla:0', grad_fn=<NllLossBackward0>) 14\ntensor(1.5375, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5424, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5608, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5545, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5475, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5568, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5482, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5595, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5502, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5449, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5476, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5436, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5583, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5495, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5500, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5469, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5460, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5434, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5462, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5470, device='xla:0', grad_fn=<NllLossBackward0>) 15\ntensor(1.5433, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5643, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5481, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5358, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5592, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5448, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5412, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5437, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5529, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5401, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5682, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5415, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5536, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5437, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5507, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5522, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5416, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5393, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5359, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5518, device='xla:0', grad_fn=<NllLossBackward0>) 16\ntensor(1.5387, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5487, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5548, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5488, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5525, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5377, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5429, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5343, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5512, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5531, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5422, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5434, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5430, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5448, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5416, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5405, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5348, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5456, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5576, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5386, device='xla:0', grad_fn=<NllLossBackward0>) 17\ntensor(1.5231, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5432, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5516, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5466, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5450, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5369, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5518, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5348, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5376, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5494, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5453, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5363, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5323, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5357, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5487, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5394, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5407, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5381, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5315, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5351, device='xla:0', grad_fn=<NllLossBackward0>) 18\ntensor(1.5340, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5382, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5416, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5265, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5331, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5356, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5375, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5287, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5398, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5189, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5272, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5396, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5247, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5222, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5326, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5423, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5513, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5316, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5423, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5400, device='xla:0', grad_fn=<NllLossBackward0>) 19\ntensor(1.5375, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5337, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5288, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5477, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5469, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5276, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5386, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5263, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5365, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5132, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5285, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5322, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5166, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5327, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5335, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5057, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5355, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5419, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5128, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5297, device='xla:0', grad_fn=<NllLossBackward0>) 20\ntensor(1.5259, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5350, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5239, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5279, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5196, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5268, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5351, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5283, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5338, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5350, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5248, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5314, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5329, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5303, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5159, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5288, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5298, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5307, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5325, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5294, device='xla:0', grad_fn=<NllLossBackward0>) 21\ntensor(1.5245, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5129, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5298, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5233, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5202, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5272, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5179, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5321, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5248, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5289, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5247, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5159, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5366, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5100, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5203, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5248, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5233, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5257, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5250, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5172, device='xla:0', grad_fn=<NllLossBackward0>) 22\ntensor(1.5212, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5217, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5149, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5097, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5122, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5187, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5270, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5139, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5156, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5117, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5224, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5265, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5059, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5179, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5167, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5107, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5204, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5141, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5235, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5121, device='xla:0', grad_fn=<NllLossBackward0>) 23\ntensor(1.5309, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5165, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5244, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5153, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5209, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5219, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5028, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5205, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5012, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5118, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5041, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5243, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5061, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5118, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5220, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5278, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5051, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5165, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5196, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.5098, device='xla:0', grad_fn=<NllLossBackward0>) 24\ntensor(1.4986, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5058, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5159, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5172, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5108, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5247, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5121, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.4933, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5103, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5098, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5018, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5121, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5026, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5169, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5112, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5142, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5107, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5083, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.4930, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.4981, device='xla:0', grad_fn=<NllLossBackward0>) 25\ntensor(1.5121, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5052, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5171, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5133, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5016, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5048, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5104, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5036, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5077, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5097, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5082, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5006, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5046, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.4949, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5077, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5084, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5117, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.4886, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.4935, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.5140, device='xla:0', grad_fn=<NllLossBackward0>) 26\ntensor(1.4947, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4933, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5088, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5020, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5028, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5043, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4945, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5020, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4972, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5118, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4904, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5146, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5168, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4941, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5110, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5045, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.4903, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5040, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5113, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5134, device='xla:0', grad_fn=<NllLossBackward0>) 27\ntensor(1.5015, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5011, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4954, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5001, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4940, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4966, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4996, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4994, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5097, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5148, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4889, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4808, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5023, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5168, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4835, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5004, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4924, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5033, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5040, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.4976, device='xla:0', grad_fn=<NllLossBackward0>) 28\ntensor(1.5049, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4983, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4796, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4942, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5032, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4989, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4966, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4944, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4804, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5054, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4968, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4990, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4952, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4898, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5047, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5014, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4908, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5008, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.5001, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4967, device='xla:0', grad_fn=<NllLossBackward0>) 29\ntensor(1.4950, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4993, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4961, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4914, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4900, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4981, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4955, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4748, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.5176, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4898, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4895, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4984, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.5051, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4863, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4881, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.5069, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4920, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4716, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4839, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4980, device='xla:0', grad_fn=<NllLossBackward0>) 30\ntensor(1.4818, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4895, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4882, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4869, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4913, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4821, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4777, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4933, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4903, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4812, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4890, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4978, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4854, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4872, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4949, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4861, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4848, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.5021, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4819, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.4924, device='xla:0', grad_fn=<NllLossBackward0>) 31\ntensor(1.5021, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4925, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4769, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4822, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4886, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4844, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4996, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4780, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4830, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4721, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4799, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4791, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4839, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4832, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4831, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4882, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4850, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4764, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4777, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4841, device='xla:0', grad_fn=<NllLossBackward0>) 32\ntensor(1.4792, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4830, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4774, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4887, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4905, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4827, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4777, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4712, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4816, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4844, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4907, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4834, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4795, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4815, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4822, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4833, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4651, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4760, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4733, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4918, device='xla:0', grad_fn=<NllLossBackward0>) 33\ntensor(1.4832, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4736, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4670, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4778, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4810, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4906, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4912, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4800, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4824, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4788, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4601, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4711, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4755, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4790, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4732, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4687, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4816, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4776, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4575, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4627, device='xla:0', grad_fn=<NllLossBackward0>) 34\ntensor(1.4762, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4657, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4692, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4748, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4738, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4722, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4898, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4761, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4963, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.5010, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4817, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4723, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4795, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4728, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4812, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4697, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4922, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4737, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4711, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4763, device='xla:0', grad_fn=<NllLossBackward0>) 35\ntensor(1.4783, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4693, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4779, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4812, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4782, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4853, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4712, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4804, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4734, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4891, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4747, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4587, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4684, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4744, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4662, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4766, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4712, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4766, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4601, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4724, device='xla:0', grad_fn=<NllLossBackward0>) 36\ntensor(1.4732, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4644, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4688, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4712, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4769, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4831, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4626, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4596, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4776, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4735, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4699, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4585, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4771, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4757, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4761, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4703, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4565, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4476, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4676, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4577, device='xla:0', grad_fn=<NllLossBackward0>) 37\ntensor(1.4660, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4678, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4691, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4664, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4640, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4808, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4771, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4716, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4538, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4658, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4593, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4729, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4686, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4638, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4643, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4644, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4747, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4596, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4668, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4741, device='xla:0', grad_fn=<NllLossBackward0>) 38\ntensor(1.4585, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4744, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4849, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4615, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4603, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4627, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4468, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4573, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4648, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4600, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4531, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4666, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4474, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4531, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4583, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4568, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4522, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4647, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4609, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4669, device='xla:0', grad_fn=<NllLossBackward0>) 39\ntensor(1.4696, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4666, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4805, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4529, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4545, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4619, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4483, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4507, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4447, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4578, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4565, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4604, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4449, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4621, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4596, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4740, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4502, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4503, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4625, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4594, device='xla:0', grad_fn=<NllLossBackward0>) 40\ntensor(1.4526, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4484, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4544, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4509, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4580, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4470, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4605, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4576, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4548, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4529, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4478, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4502, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4657, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4611, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4508, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4554, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4464, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4434, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4574, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4519, device='xla:0', grad_fn=<NllLossBackward0>) 41\ntensor(1.4647, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4466, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4519, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4423, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4468, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4593, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4530, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4531, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4447, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4398, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4551, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4348, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4498, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4525, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4436, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4532, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4448, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4525, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4399, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4390, device='xla:0', grad_fn=<NllLossBackward0>) 42\ntensor(1.4485, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4449, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4420, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4356, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4411, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4507, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4603, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4562, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4447, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4694, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4509, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4482, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4481, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4490, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4518, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4501, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4378, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4455, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4418, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4412, device='xla:0', grad_fn=<NllLossBackward0>) 43\ntensor(1.4369, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4707, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4497, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4435, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4374, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4360, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4462, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4501, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4398, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4491, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4335, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4480, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4542, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4485, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4356, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4443, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4513, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4452, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4301, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4225, device='xla:0', grad_fn=<NllLossBackward0>) 44\ntensor(1.4515, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4403, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4376, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4517, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4474, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4420, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4482, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4377, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4489, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4306, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4456, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4493, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4388, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4436, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4269, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4395, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4511, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4378, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4483, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4347, device='xla:0', grad_fn=<NllLossBackward0>) 45\ntensor(1.4461, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4455, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4405, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4262, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4299, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4417, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4309, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4463, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4385, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4379, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4355, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4361, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4445, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4416, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4384, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4465, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4359, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4264, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4419, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4338, device='xla:0', grad_fn=<NllLossBackward0>) 46\ntensor(1.4313, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4417, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4192, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4310, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4372, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4391, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4313, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4235, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4388, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4486, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4493, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4306, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4400, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4137, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4144, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4245, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4222, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4361, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4224, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4456, device='xla:0', grad_fn=<NllLossBackward0>) 47\ntensor(1.4375, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4233, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4267, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4391, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4281, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4299, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4279, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4296, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4072, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4401, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4337, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4393, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4262, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4235, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4319, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4478, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4363, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4352, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4280, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4288, device='xla:0', grad_fn=<NllLossBackward0>) 48\ntensor(1.4384, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4210, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4176, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4322, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4190, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4248, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4316, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4268, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4261, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4291, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4289, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4187, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4355, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4228, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4210, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4313, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4320, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4311, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4431, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4269, device='xla:0', grad_fn=<NllLossBackward0>) 49\ntensor(1.4314, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4334, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4297, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4187, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4167, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4343, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4199, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4102, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4283, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4265, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4264, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4358, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4420, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4234, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4245, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4150, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4408, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4236, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4348, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4362, device='xla:0', grad_fn=<NllLossBackward0>) 50\ntensor(1.4321, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4365, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4171, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4217, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4217, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4292, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4188, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4285, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4350, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4240, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4330, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4255, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4251, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4147, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4343, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4192, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4193, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4137, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4321, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4118, device='xla:0', grad_fn=<NllLossBackward0>) 51\ntensor(1.4150, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4207, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4238, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4246, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4188, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4276, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4102, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4078, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4107, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4293, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4146, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4129, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4300, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4383, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4283, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4185, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4092, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4257, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4191, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4191, device='xla:0', grad_fn=<NllLossBackward0>) 52\ntensor(1.4155, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4217, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4311, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4108, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4155, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4333, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4250, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4177, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4123, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4149, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4180, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4199, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4167, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4143, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4264, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4113, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4198, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4231, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4245, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4076, device='xla:0', grad_fn=<NllLossBackward0>) 53\ntensor(1.4190, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4087, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4149, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4149, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4135, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4155, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4329, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4158, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4202, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4189, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4143, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4107, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4033, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4122, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4153, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4085, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4238, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4129, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4054, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4195, device='xla:0', grad_fn=<NllLossBackward0>) 54\ntensor(1.4251, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4071, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4060, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4090, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4014, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4093, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4227, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4118, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4055, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4003, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4142, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4032, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.3873, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4154, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4085, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.3987, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4212, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4134, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4109, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4121, device='xla:0', grad_fn=<NllLossBackward0>) 55\ntensor(1.4019, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4017, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4148, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4086, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.3955, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4125, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4120, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4160, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.3962, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4009, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4111, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4120, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4131, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.3880, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4223, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4161, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4075, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4084, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.4148, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.3920, device='xla:0', grad_fn=<NllLossBackward0>) 56\ntensor(1.3935, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4103, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4003, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4003, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4067, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4076, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4136, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4083, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4146, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.3882, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4114, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4001, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4127, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.3974, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4275, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4060, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.3907, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4065, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4094, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.3972, device='xla:0', grad_fn=<NllLossBackward0>) 57\ntensor(1.4006, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4013, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4131, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4153, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4031, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4015, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3968, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3980, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3980, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3972, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3998, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4022, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3880, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4137, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3980, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3951, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4033, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4007, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4030, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.3996, device='xla:0', grad_fn=<NllLossBackward0>) 58\ntensor(1.4157, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3972, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3877, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4072, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4038, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3924, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4013, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4049, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4090, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4080, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3935, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4080, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3955, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4081, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3994, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3984, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.4184, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3918, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3889, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3956, device='xla:0', grad_fn=<NllLossBackward0>) 59\ntensor(1.3910, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4010, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4018, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4106, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4006, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3977, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3964, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4106, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3974, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3908, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3946, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3795, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3993, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4057, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.4031, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3907, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3992, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3937, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3999, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3991, device='xla:0', grad_fn=<NllLossBackward0>) 60\ntensor(1.3947, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.4035, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.4005, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3920, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3806, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3888, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3922, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3990, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.4004, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.4013, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.4116, device='xla:0', grad_fn=<NllLossBackward0>) 61\ntensor(1.3996, device='xla:0', grad_fn=<NllLossBackward0>) 61\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 39\u001B[0m\n\u001B[1;32m     36\u001B[0m             torch\u001B[38;5;241m.\u001B[39msave(gpt\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrained_model_after_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m90\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_epochs_4gramm.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     38\u001B[0m FLAGS\u001B[38;5;241m=\u001B[39m{}\n\u001B[0;32m---> 39\u001B[0m \u001B[43mxmp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_mp_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mFLAGS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfork\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/runtime.py:82\u001B[0m, in \u001B[0;36mrequires_pjrt.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_pjrt():\n\u001B[1;32m     79\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m` not implemented for XRT\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     80\u001B[0m       fn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m))\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/distributed/xla_multiprocessing.py:38\u001B[0m, in \u001B[0;36mspawn\u001B[0;34m(fn, args, nprocs, join, daemon, start_method)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;129m@xr\u001B[39m\u001B[38;5;241m.\u001B[39mrequires_pjrt\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mspawn\u001B[39m(fn,\n\u001B[1;32m      8\u001B[0m           args\u001B[38;5;241m=\u001B[39m(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     11\u001B[0m           daemon\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     12\u001B[0m           start_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     13\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Enables multi processing based replication.\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m    return None.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpjrt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mspawn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnprocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/_internal/pjrt.py:198\u001B[0m, in \u001B[0;36mspawn\u001B[0;34m(fn, nprocs, start_method, args)\u001B[0m\n\u001B[1;32m    195\u001B[0m spawn_fn \u001B[38;5;241m=\u001B[39m _SpawnFn(fn, \u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nprocs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 198\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_run_singleprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspawn_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m nprocs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m   logging\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnsupported nprocs (\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m), ignoring...\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m nprocs)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/runtime.py:82\u001B[0m, in \u001B[0;36mrequires_pjrt.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m using_pjrt():\n\u001B[1;32m     79\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m` not implemented for XRT\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     80\u001B[0m       fn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m))\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/_internal/pjrt.py:102\u001B[0m, in \u001B[0;36m_run_singleprocess\u001B[0;34m(fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     98\u001B[0m   tpu\u001B[38;5;241m.\u001B[39mconfigure_one_chip_topology()\n\u001B[1;32m    100\u001B[0m xm\u001B[38;5;241m.\u001B[39mset_replication(xm\u001B[38;5;241m.\u001B[39mxla_device(), [])\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch_xla/_internal/pjrt.py:178\u001B[0m, in \u001B[0;36m_SpawnFn.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 178\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mruntime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mglobal_ordinal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[29], line 34\u001B[0m, in \u001B[0;36m_mp_fn\u001B[0;34m(rank, flags)\u001B[0m\n\u001B[1;32m     32\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     33\u001B[0m     xm\u001B[38;5;241m.\u001B[39moptimizer_step(optimizer)\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;43mprint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (epoch \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m     36\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(gpt\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrained_model_after_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m90\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_epochs_4gramm.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:431\u001B[0m, in \u001B[0;36mTensor.__repr__\u001B[0;34m(self, tensor_contents)\u001B[0m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    428\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__repr__\u001B[39m, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, tensor_contents\u001B[38;5;241m=\u001B[39mtensor_contents\n\u001B[1;32m    429\u001B[0m     )\n\u001B[1;32m    430\u001B[0m \u001B[38;5;66;03m# All strings are unicode in Python 3.\u001B[39;00m\n\u001B[0;32m--> 431\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tensor_str\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_str\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor_str.py:664\u001B[0m, in \u001B[0;36m_str\u001B[0;34m(self, tensor_contents)\u001B[0m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39m_python_dispatch\u001B[38;5;241m.\u001B[39m_disable_current_modes():\n\u001B[1;32m    663\u001B[0m     guard \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_DisableFuncTorch()\n\u001B[0;32m--> 664\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_str_intern\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensor_contents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_contents\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor_str.py:430\u001B[0m, in \u001B[0;36m_str_intern\u001B[0;34m(inp, tensor_contents)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;66;03m# Tensor printing performs tensor operations like slice, indexing, etc to make it in a\u001B[39;00m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;66;03m# representable format. These operations on ipu/xla/lazy/mtia tensor results in compilations. Hence,\u001B[39;00m\n\u001B[1;32m    428\u001B[0m \u001B[38;5;66;03m# to avoid compilations, copying the tensor to cpu before printing.\u001B[39;00m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlazy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mipu\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmtia\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 430\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;66;03m# TODO: add an API to map real -> complex dtypes\u001B[39;00m\n\u001B[1;32m    433\u001B[0m _default_complex_dtype \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    434\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcdouble \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mget_default_dtype() \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39mdouble \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcfloat\n\u001B[1;32m    435\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
